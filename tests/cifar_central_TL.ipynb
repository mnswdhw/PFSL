{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR10_iid(datapoints, path):\n",
    "\n",
    "\n",
    "    #these transforms are same as Imagenet configurations as TL is being used\n",
    "    custom_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=path,\n",
    "                                            train=True,\n",
    "                                            transform=custom_transform,download= True)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=path,\n",
    "                                            train=False,\n",
    "                                            transform=custom_transform, download = True)\n",
    "    \n",
    "    class2idx = train_dataset.class_to_idx.items()\n",
    "    idx2class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "    \n",
    "    new_train_dataset_size =  datapoints\n",
    "    temp = len(train_dataset) - new_train_dataset_size\n",
    "\n",
    "    print(len(train_dataset), new_train_dataset_size, temp)\n",
    "\n",
    "    new_train_dataset,_ = torch.utils.data.random_split(train_dataset, (new_train_dataset_size, temp))\n",
    "    new_test_dataset,_ = torch.utils.data.random_split(test_dataset, (2000, 8000))  #keeping 2k datapoints with each client\n",
    "\n",
    "    return new_train_dataset, new_test_dataset, dict(class2idx), idx2class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m CIFAR10_iid(\u001b[39m500\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m, in \u001b[0;36mCIFAR10_iid\u001b[0;34m(datapoints, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mCIFAR10_iid\u001b[39m(datapoints, path):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m     \u001b[39m#these transforms are same as Imagenet configurations as TL is being used\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     custom_transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      6\u001b[0m         transforms\u001b[39m.\u001b[39mResize((\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)),\n\u001b[1;32m      7\u001b[0m         transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      8\u001b[0m         transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m],\n\u001b[1;32m      9\u001b[0m                                 std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])\n\u001b[1;32m     10\u001b[0m     ])\n\u001b[0;32m---> 11\u001b[0m     train_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(root\u001b[39m=\u001b[39mpath,\n\u001b[1;32m     12\u001b[0m                                             train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                             transform\u001b[39m=\u001b[39mcustom_transform,download\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     test_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(root\u001b[39m=\u001b[39mpath,\n\u001b[1;32m     16\u001b[0m                                             train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m                                             transform\u001b[39m=\u001b[39mcustom_transform, download \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     class2idx \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mclass_to_idx\u001b[39m.\u001b[39mitems()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CIFAR10_iid(500, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataLoader(train_dataset, test_dataset, train_batch_size, test_batch_size):\n",
    "    train_batch_size = train_batch_size\n",
    "    test_batch_size = test_batch_size\n",
    "    train_DataLoader = torch.utils.data.DataLoader(dataset= train_dataset,\n",
    "                                            batch_size=train_batch_size,\n",
    "                                            shuffle=True)\n",
    "    test_DataLoader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=test_batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "    return train_DataLoader, test_DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512,10,bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# for param in model.layer3.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed!\n",
      "Epoch: 000/011 | Train: 75.450% | Loss: 0.716\n",
      "Epoch: 000/011 | Test: 71.670%\n",
      "Time elapsed: 0.48 min\n",
      "Epoch 1 completed!\n",
      "Time elapsed: 0.78 min\n",
      "Epoch 2 completed!\n",
      "Epoch: 002/011 | Train: 86.280% | Loss: 0.399\n",
      "Epoch: 002/011 | Test: 77.930%\n",
      "Time elapsed: 1.24 min\n",
      "Epoch 3 completed!\n",
      "Time elapsed: 1.54 min\n",
      "Epoch 4 completed!\n",
      "Epoch: 004/011 | Train: 91.742% | Loss: 0.241\n",
      "Epoch: 004/011 | Test: 79.940%\n",
      "Time elapsed: 2.02 min\n",
      "Epoch 5 completed!\n",
      "Time elapsed: 2.32 min\n",
      "Epoch 6 completed!\n",
      "Epoch: 006/011 | Train: 96.294% | Loss: 0.116\n",
      "Epoch: 006/011 | Test: 80.900%\n",
      "Time elapsed: 2.77 min\n",
      "Epoch 7 completed!\n",
      "Time elapsed: 3.08 min\n",
      "Epoch 8 completed!\n",
      "Epoch: 008/011 | Train: 97.194% | Loss: 0.084\n",
      "Epoch: 008/011 | Test: 80.460%\n",
      "Time elapsed: 3.53 min\n",
      "Epoch 9 completed!\n",
      "Time elapsed: 3.84 min\n",
      "Epoch 10 completed!\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        logits = model(features)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "\n",
    "\n",
    "def compute_epoch_loss(model, data_loader):\n",
    "    model.eval()\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits = model(features)\n",
    "            loss = F.cross_entropy(logits, targets, reduction='sum')\n",
    "            num_examples += targets.size(0)\n",
    "            curr_loss += loss\n",
    "\n",
    "        curr_loss = curr_loss / num_examples\n",
    "        return curr_loss\n",
    "    \n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch} completed!\")\n",
    "    \n",
    "    if epoch%2 == 0:\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False): # save memory during inference\n",
    "            print('Epoch: %03d/%03d | Train: %.3f%% | Loss: %.3f' % (\n",
    "                  epoch, num_epochs+1, \n",
    "                  compute_accuracy(model, train_loader),\n",
    "                  compute_epoch_loss(model, train_loader)))\n",
    "\n",
    "        with torch.set_grad_enabled(False): # save memory during inference\n",
    "            print('Epoch: %03d/%03d | Test: %.3f%%' % (\n",
    "                  epoch, num_epochs+1, \n",
    "                  compute_accuracy(model, test_loader)))\n",
    "        \n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('priv_slr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb2723f71081179efcf831066f68fa5cac5645e8c6a76cceb0fa7f634ae4f593"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
